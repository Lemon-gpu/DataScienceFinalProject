{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d17ee11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lemon/anaconda3/envs/Project/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "读取评论文件的评论信息\n",
    "\"\"\"\n",
    "def read_files(filePath: str) -> pd.DataFrame:\n",
    "    result = pd.DataFrame()\n",
    "    for file in os.listdir(filePath):\n",
    "        if file.endswith(\".csv\"):\n",
    "            temp = pd.read_csv(os.path.join(filePath, file))\n",
    "            result = pd.concat([result, temp])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a58be",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_data = read_files('dataset/subset')\n",
    "len(comments_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081935a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d716d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.8\n",
    "split_line = int(len(comments_data) * split)\n",
    "split_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c7d616",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'                     # 获取GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f6a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集与测试集，并将pandas数据类型转化为列表类型\n",
    "train_comments, train_labels = list(comments_data[: split_line, 0]), list(comments_data[: split_line, 1])\n",
    "test_comments, test_labels = list(comments_data[split_line:, 0]), list(comments_data[split_line:, 1])\n",
    "\n",
    "len(train_comments),len(train_labels), len(test_comments), len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4952c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step2: 定义BERTClassifier分类器模型\n",
    "\"\"\"\n",
    "class BERTClassifier(nn.Module):\n",
    "\n",
    "    # 初始化加载 bert-base-chinese 原型，即Bert中的Bert-Base模型\n",
    "    def __init__(self, output_dim, pretrained_name='bert-base-chinese'):\n",
    "\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        \n",
    "        # 定义 Bert 模型\n",
    "        self.bert = BertModel.from_pretrained(pretrained_name)\n",
    "\n",
    "        # 外接全连接层\n",
    "        self.mlp = nn.Linear(768, output_dim)\n",
    "\n",
    "\n",
    "    def forward(self, tokens_X: dict[str, torch.Tensor]):\n",
    "\n",
    "        # 得到最后一层的 '<cls>' 信息， 其标志全部上下文信息\n",
    "        res = self.bert(**tokens_X)\n",
    "\n",
    "        # res[1]代表序列的上下文信息'<cls>'，外接全连接层，进行情感分析 \n",
    "        return self.mlp(res[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "评估函数，用以评估数据集在神经网络下的精确度\n",
    "\"\"\"\n",
    "def evaluate(net, comments_data, labels_data):\n",
    "    \n",
    "    sum_correct, i = 0, 0\n",
    "    \n",
    "    while i <= len(comments_data):\n",
    "        \n",
    "        comments = comments_data[i: min(i + 8, len(comments_data))]\n",
    "        \n",
    "        tokens_X = BertTokenizer(comments, padding=True, truncation=True, return_tensors='pt').to(device=device)\n",
    "\n",
    "        res = net(tokens_X)                                          # 获得到预测结果\n",
    "\n",
    "        y = torch.tensor(labels_data[i: min(i + 8, len(comments_data))]).reshape(-1).to(device=device)\n",
    "\n",
    "        sum_correct += (res.argmax(axis=1) == y).sum()              # 累加预测正确的结果\n",
    "        i += 8\n",
    "\n",
    "    return sum_correct/len(comments_data)                           # 返回(总正确结果/所有样本)，精确率\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "训练bert_classifier分类器\n",
    "\n",
    "\"\"\"\n",
    "def train_bert_classifier(net, tokenizer, loss, optimizer, train_comments, train_labels, test_comments, test_labels, device, epochs):\n",
    "    \n",
    "    max_acc = 0.5                                 # 初始化模型最大精度为0.5\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        \n",
    "        i, sum_loss = 0, 0                           # 每次开始训练时， i 为0 表示从第一条数据开始训练\n",
    "        \n",
    "        # 计算训练集与测试集的精度\n",
    "        train_acc = evaluate(net, train_comments, train_labels)\n",
    "        test_acc = evaluate(net, test_comments, test_labels)\n",
    "        \n",
    "        # 输出精度\n",
    "        print('\\n--epoch', epoch, '\\t--loss:', sum_loss / (len(train_comments) / 8), '\\t--train_acc:', train_acc, '\\t--test_acc', test_acc)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 如果测试集精度 大于 之前保存的最大精度，保存模型参数，并重设最大值\n",
    "        if test_acc > max_acc:\n",
    "            \n",
    "            # 更新历史最大精确度\n",
    "            max_acc = test_acc\n",
    "            \n",
    "            # 保存模型\n",
    "            torch.save(net.state_dict(), 'bert.parameters')\n",
    "        \n",
    "        \n",
    "        # 开始训练模型\n",
    "        while i < len(comments_data):\n",
    "            comments = train_comments[i: min(i+8, len(train_comments))]             # 批量训练，每次训练8条样本数据\n",
    "\n",
    "            # 通过 tokenizer 数据化输入的评论语句信息，准备输入bert分类器\n",
    "            # 输入的8个评论语句长度很可能不一致，这时取长度为最长的那个句子，padding=True代表对短句子进行填充操作\n",
    "            # 当输入的某个句子过长时，使用truncation=True进行截断操作\n",
    "            # return_tensors='pt' 代表返回的数据类型为 python 的 torch 类型\n",
    "            tokens_X = tokenizer(comments, padding=True, truncation=True, return_tensors='pt').to(device=device)\n",
    "\n",
    "            # 将数据输入到bert分类器模型中，获得结果\n",
    "            res = net(tokens_X)\n",
    "\n",
    "            # 批量获取实际结果信息\n",
    "            y = torch.tensor(train_labels[i: min(i+8, len(train_comments))]).reshape(-1).to(device=device)\n",
    "\n",
    "            optimizer.zero_grad()                  # 清空梯度\n",
    "            l = loss(res, y)                       # 计算损失\n",
    "            l.backward()                           # 后向传播\n",
    "            optimizer.step()                      # 更新梯度\n",
    "\n",
    "            sum_loss += l.detach()                # 累加损失\n",
    "            i += 8                                # 样本下标累加\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98d00f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "net = BERTClassifier(output_dim=3)                      # BERTClassifier分类器，因为最终结果为3分类，所以输出维度为3，代表概率分布\n",
    "net = net.to(device)\n",
    "\n",
    "# 定义tokenizer对象，用于将评论语句转化为BertModel的输入信息\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "\n",
    "loss = nn.CrossEntropyLoss()                            # 损失函数\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-4)      # 小批量随机梯度下降算法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0016b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bert_classifier(net, tokenizer, loss, optimizer, train_comments, train_labels, test_comments, test_labels, device, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
